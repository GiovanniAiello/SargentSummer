%!TEX root = ../marching3.tex

\begin{homeworkProblem}[Problem 5.2]

  Verify that equations 5.2.10 and 5.2.11 implement the policy improvement algorithm for the discounted linear regulator problem.

  \vspace{.2in}

  \problemAnswer{

    Before showing the solution to this problem I need to define a few things:

    \begin{itemize}
      \item The value function is represented as $v(x)_t = -x_t'P_tx_t$.
      \item The policy is of the form: $u_t = F_t x_t$
      \item The Bellman is of the following form:
        \begin{align} \label{eq:p2e1}
          V(x) &= - x_t' R x_t - u_t' Q u_t - \beta(Ax_t + Bu_t)' P_t(Ax_t  + Bu_t) \\
            &= - x_t' R x_t - x_t'F_t' Q F_tx_t - \beta(Ax_t + B F_t x_t)' P_t(A x_t  + B F_tx_t) \\
            &= - x_t' R x_t - x_t'(F_t' Q F_t) x_t - \beta x_t' \left((A + B F_t)' P_t(A  + B F_t)\right)x_t
        \end{align}
      \item The first order conditions for the Bellman are given in equation 5.2.3 (with a $\beta$ added where needed -- see Problem 5.1 for the work), which I repeat here: $$\left(Q + \beta B'P_tB \right)u_{t+1} = -\beta B'P_tAx_t$$
    \end{itemize}

    With those items set up, I am ready to begin. I assume that I have an optimal policy of the form $u_0 = - F_0 x_0$.  I know that my goal is to end up at the policy improvement algorithm, so I will assume I will apply that policy forever. In doing this I  will need to verify that the eigenvalues of $A - BF_0$ are all less than $\frac{1}{\sqrt{\beta}}$ in modulus; this will ensure that the problem doesn't go off to infinity. The next step is to take the expression for the Bellman in Equation \ref{eq:p2e1}, set it equal to the value function from above, equate terms, and get an implicit expression for $P_0$.  I do this below.

    \begin{align} \label{eq:p2e2}
      v(x)_0 &= V(x)_0 \\
        -x_0' P_0 x_0 &= - x_0' R x_0 - x_0'(F_0' Q F_0) x_0 - \beta x_0' \left((A + B F_0)' P_0(A  + B F_0)\right)x_0\\
        P_0 &=  R  + F_0' Q F_0 + \beta  (A - B F_0)' P_0(A  - B F_0)
    \end{align}

    I can now use the first order conditions for this equation solve for $u_1$ like so:

    \begin{align} \label{eq:p2e3}
      \left(Q + \beta B'P_tB \right)u_1 &= -\beta B'P_0Ax_0 \\
      u_1 &= - \beta \left(Q + \beta B'P_0B \right)^{-1}B'P_0Ax_0 \\
      u_1 = -F_1 x_t
    \end{align}

    Where

    \begin{align} \label{eq:p2e4}
      F_1 = \beta \left(Q + \beta B'P_0B \right)^{-1}B'P_0
    \end{align}

    Together Equations \ref{eq:p2e2} and \ref{eq:p2e4} define a recursion for $P_t$ and $F_J$, which I repeat here for completeness:

    \begin{align} \label{eq:p2e5}
      P_t &=  R  + F_t' Q F_t + \beta  (A - B F_t)' P_t(A  - B F_t) \\
      F_{t+1} &= \beta \left(Q + \beta B'P_tB \right)^{-1}B'P_t
    \end{align}

    These equations are the same as 5.2.10 and 5.2.11 and were derived using the policy improvement algorithm. \qed

  }

\end{homeworkProblem}
